{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "general-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "material-kelly",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-emotion.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b552918a3784c1a9cb2815aafae32ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/589 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a37f64797d44e1a58d311141b666de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-irony.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4984d69a9ce04ebfad4d1d8a33069927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ea801ec20c4e10abafa786d27d2d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeac2d98dd8a4f339352ba48fc65c200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "\n",
    "task1='emotion'\n",
    "MODEL1 = f\"cardiffnlp/twitter-roberta-base-{task1}\"\n",
    "model1 = TFAutoModelForSequenceClassification.from_pretrained(MODEL1)\n",
    "tokenizer1 = AutoTokenizer.from_pretrained(MODEL1)\n",
    "\n",
    "task2='irony'\n",
    "MODEL2 = f\"cardiffnlp/twitter-roberta-base-{task2}\"\n",
    "model2 = TFAutoModelForSequenceClassification.from_pretrained(MODEL2)\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(MODEL2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "textile-insulin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger', 'joy', 'optimism', 'sadness']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download label mapping emotion\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task1}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels1 = [row[1] for row in csvreader if len(row) > 1]\n",
    "labels1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "threaded-holder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non_irony', 'irony']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download label mapping irony\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task2}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels2 = [row[1] for row in csvreader if len(row) > 1]\n",
    "labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "expensive-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PT\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "#text = \"Good night ðŸ˜Š\"\n",
    "#text = preprocess(text)\n",
    "#encoded_input = tokenizer(text, return_tensors='pt')\n",
    "#output = model(**encoded_input)\n",
    "#scores = output[0][0].detach().numpy()\n",
    "#scores = softmax(scores)\n",
    "\n",
    "# # TF\n",
    "text1 = \"Good night ðŸ˜Š\"\n",
    "encoded_input1 = tokenizer1(text1, return_tensors='tf')\n",
    "output1 = model1(encoded_input)\n",
    "scores1 = output[0][0].numpy()\n",
    "scores1 = softmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "whole-network",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) joy 0.3622\n",
      "2) sadness 0.2488\n",
      "3) optimism 0.1955\n",
      "4) anger 0.1935\n"
     ]
    }
   ],
   "source": [
    "ranking1 = np.argsort(scores1)\n",
    "ranking1 = ranking1[::-1]\n",
    "for i in range(scores1.shape[0]):\n",
    "    l1 = labels1[ranking1[i]]\n",
    "    s1 = scores1[ranking1[i]]\n",
    "    print(f\"{i+1}) {l1} {np.round(float(s1), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "attempted-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"Good night #noooot\"\n",
    "encoded_input2 = tokenizer2(text2, return_tensors='tf')\n",
    "output2 = model2(encoded_input)\n",
    "scores2 = output[0][0].numpy()\n",
    "scores2 = softmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "arabic-numbers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) irony 0.3622\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-ea0ca9845601>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mranking2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mranking2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0ml2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mranking2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0ms2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mranking2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{i+1}) {l2} {np.round(float(s2), 4)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "ranking2 = np.argsort(scores2)\n",
    "ranking2 = ranking2[::-1]\n",
    "for i in range(scores2.shape[0]):\n",
    "    l2 = labels2[ranking2[i]]\n",
    "    s2 = scores2[ranking2[i]]\n",
    "    print(f\"{i+1}) {l2} {np.round(float(s2), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "educational-theta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) irony 0.6547\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-fb74a74370d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mranking2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mranking2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0ml2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mranking2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0ms2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mranking2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{i+1}) {l} {np.round(float(s), 4)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-embassy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
